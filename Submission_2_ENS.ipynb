{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccd3afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41383566f2e343058fb859fa24bcb464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building features:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae4945738c048398e031f4d6c67d11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Building features:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FINAL] train_df: (10000, 66)\n",
      "[FINAL] test_df : (5000, 65)\n"
     ]
    }
   ],
   "source": [
    "# This code has been produced by the group \"team_pk\" group, composed of Leonardo Suriano, Riccardo Pugliese and Mariana Dos Campos.\n",
    "# In the code we have provided some comments, that aims to help the reader moving around the code and get what the code is doing.\n",
    "# The whole explanation has been given for each step of the code, from the building features code to the final predictive model. \n",
    "# Moreover, we decided to import libraries not all at once, but to import in every cell the libraries that the cell is using. This choice \n",
    "# has been made in order to make clear which library has been used in that specific cell.\n",
    "# In case the comments we added are not enough to satisfy your curiosity, and in case you may need further clarification about function\n",
    "# taken from libraries, please refer to the documentation of the respective libraries.\n",
    "# In case you need further clarification about function we created from scratch in our code or about how the libraries functions has\n",
    "# been used, please feel free to contact us. We will be more than happy to answer all your doubt!!!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# AI assistance disclaimer\n",
    "# Parts of this code (in particular some comments, the iterative feature search, and minor implementation details) may have been drafted or refined \n",
    "# with the help of AI-based tools. The use of AI was strictly limited to these aspects. All core ideas, modeling choices, and logical structures \n",
    "# implemented in the code and in the models were entirely conceived and designed by the members of the group, without external intellectual \n",
    "# contribution, relying solely on online documentation, our own knowledge and the insights provided by the course lectures.\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# In this first cell, we are doing the following operations:\n",
    "#   - read the raw battle logs from train.jsonl and test.jsonl\n",
    "#   - define Pokémon stats (species) and types\n",
    "#   - define the type chart (which type is strong/weak vs which other type)\n",
    "#   - create helper functions for:\n",
    "#       1) safe division\n",
    "#       2) type effectiveness scoring\n",
    "#       3) counting statuses, switches, damage, etc.\n",
    "#   - define and call build_features(dataset) to create:\n",
    "#       * train_df (features + target player_won)\n",
    "#       * test_df  (features only, we must predict player_won)\n",
    "# ============================================================\n",
    "\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# =========================\n",
    "# Train and test dataset input paths\n",
    "# =========================\n",
    "\n",
    "DATA_DIR   = Path(r\"C:\\Users\\2003l\\OneDrive\\Documenti\\fds-pokemon-battles-prediction-2025\")\n",
    "TRAIN_FILE = DATA_DIR / \"train.jsonl\"   \n",
    "TEST_FILE  = DATA_DIR / \"test.jsonl\" \n",
    "\n",
    "# Small helper: read a .jsonl file (one JSON per line) into a Python list.\n",
    "# Each line in the file is a JSON object = one battle.\n",
    "def load_jsonl(path: Path):\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "# Load train and test battles into memory as Python lists of dicts.\n",
    "train_data = load_jsonl(TRAIN_FILE)\n",
    "test_data  = load_jsonl(TEST_FILE)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Below, we are creating a dictionary of base stats for each Pokémon in our battles.\n",
    "# For each species we store:\n",
    "#   hp  = base HP\n",
    "#   atk = attack\n",
    "#   def = defense\n",
    "#   spa = special attack\n",
    "#   spd = special defense\n",
    "#   spe = speed\n",
    "# We will use these numbers to compute the features that need \"edges\",\n",
    "# like speed advantage, attack advantage, defense advantage, etc.\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "species = {\n",
    "    'alakazam': {'hp': 55, 'atk': 50, 'def': 45, 'spa': 135, 'spd': 135, 'spe': 120},\n",
    "    'articuno': {'hp': 90, 'atk': 85, 'def': 100, 'spa': 125, 'spd': 125, 'spe': 85},\n",
    "    'chansey': {'hp': 250, 'atk': 5, 'def': 5, 'spa': 105, 'spd': 105, 'spe': 50},\n",
    "    'charizard': {'hp': 78, 'atk': 84, 'def': 78, 'spa': 85, 'spd': 85, 'spe': 100},\n",
    "    'cloyster': {'hp': 50, 'atk': 95, 'def': 180, 'spa': 85, 'spd': 85, 'spe': 70},\n",
    "    'dragonite': {'hp': 91, 'atk': 134, 'def': 95, 'spa': 100, 'spd': 100, 'spe': 80},\n",
    "    'exeggutor': {'hp': 95, 'atk': 95, 'def': 85, 'spa': 125, 'spd': 125, 'spe': 55},\n",
    "    'gengar': {'hp': 60, 'atk': 65, 'def': 60, 'spa': 130, 'spd': 130, 'spe': 110},\n",
    "    'golem': {'hp': 80, 'atk': 110, 'def': 130, 'spa': 55, 'spd': 55, 'spe': 45},\n",
    "    'jolteon': {'hp': 65, 'atk': 65, 'def': 60, 'spa': 110, 'spd': 110, 'spe': 130},\n",
    "    'jynx': {'hp': 65, 'atk': 50, 'def': 35, 'spa': 95, 'spd': 95, 'spe': 95},\n",
    "    'lapras': {'hp': 130, 'atk': 85, 'def': 80, 'spa': 95, 'spd': 95, 'spe': 60},\n",
    "    'persian': {'hp': 65, 'atk': 70, 'def': 60, 'spa': 65, 'spd': 65, 'spe': 115},\n",
    "    'rhydon': {'hp': 105, 'atk': 130, 'def': 120, 'spa': 45, 'spd': 45, 'spe': 40},\n",
    "    'slowbro': {'hp': 95, 'atk': 75, 'def': 110, 'spa': 80, 'spd': 80, 'spe': 30},\n",
    "    'snorlax': {'hp': 160, 'atk': 110, 'def': 65, 'spa': 65, 'spd': 65, 'spe': 30},\n",
    "    'starmie': {'hp': 60, 'atk': 75, 'def': 85, 'spa': 100, 'spd': 100, 'spe': 115},\n",
    "    'tauros': {'hp': 75, 'atk': 100, 'def': 95, 'spa': 70, 'spd': 70, 'spe': 110},\n",
    "    'victreebel': {'hp': 80, 'atk': 105, 'def': 65, 'spa': 100, 'spd': 100, 'spe': 70},\n",
    "    'zapdos': {'hp': 90, 'atk': 90, 'def': 85, 'spa': 125, 'spd': 125, 'spe': 100},\n",
    "}\n",
    "\n",
    "# For each Pokémon we are storing here its typing (primary and secondary type).\n",
    "# Please nota that \"notype\" means \"no second type\" in this simplified setup.\n",
    "\n",
    "types_map = {\n",
    "    \"alakazam\": [\"notype\", \"psychic\"],\n",
    "    \"articuno\": [\"flying\", \"ice\"],\n",
    "    \"chansey\": [\"normal\", \"notype\"],\n",
    "    \"charizard\": [\"fire\", \"flying\"],\n",
    "    \"cloyster\": [\"ice\", \"water\"],\n",
    "    \"dragonite\": [\"dragon\", \"flying\"],\n",
    "    \"exeggutor\": [\"grass\", \"psychic\"],\n",
    "    \"gengar\": [\"ghost\", \"poison\"],\n",
    "    \"golem\": [\"ground\", \"rock\"],\n",
    "    \"jolteon\": [\"electric\", \"notype\"],\n",
    "    \"jynx\": [\"ice\", \"psychic\"],\n",
    "    \"lapras\": [\"ice\", \"water\"],\n",
    "    \"persian\": [\"normal\", \"notype\"],\n",
    "    \"rhydon\": [\"ground\", \"rock\"],\n",
    "    \"slowbro\": [\"psychic\", \"water\"],\n",
    "    \"snorlax\": [\"normal\", \"notype\"],\n",
    "    \"starmie\": [\"psychic\", \"water\"],\n",
    "    \"tauros\": [\"normal\", \"notype\"],\n",
    "    \"victreebel\": [\"grass\", \"poison\"],\n",
    "    \"zapdos\": [\"electric\", \"flying\"]\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Type chart: this tells us how strong one attacking type is\n",
    "# against another defending type. This is due to the fact that \n",
    "# pokemon of one specific type may be really strong on some \n",
    "# specific type of pokemon but ineffective on others.\n",
    "# An example has been provided:\n",
    "#   effectiveness['fire']['grass'] = 2   (super effective)\n",
    "#   effectiveness['normal']['rock'] = 0.5 (not very effective)\n",
    "#   effectiveness['ghost']['psychic'] = 0 (no effect)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# The following table may have been taken from internet, formatted as below and \n",
    "# copy pasted here.\n",
    "\n",
    "effectiveness = {\n",
    "    'normal':   {'rock': 0.5, 'ghost': 0, 'notype': 1},\n",
    "    'fire':     {'grass': 2, 'ice': 2, 'bug': 2, 'rock': 0.5, 'fire': 0.5, 'water': 0.5, 'dragon': 0.5},\n",
    "    'water':    {'fire': 2, 'rock': 2, 'ground': 2, 'water': 0.5, 'grass': 0.5, 'dragon': 0.5},\n",
    "    'electric': {'water': 2, 'flying': 2, 'ground': 0, 'electric': 0.5, 'grass': 0.5, 'dragon': 0.5},\n",
    "    'grass':    {'water': 2, 'rock': 2, 'ground': 2, 'fire': 0.5, 'grass': 0.5, 'poison': 0.5, 'flying': 0.5, 'dragon': 0.5},\n",
    "    'ice':      {'grass': 2, 'ground': 2, 'flying': 2, 'dragon': 2, 'fire': 0.5, 'ice': 0.5, 'water': 0.5},\n",
    "    'poison':   {'grass': 2, 'poison': 0.5, 'ground': 0.5, 'rock': 0.5, 'ghost': 0.5},\n",
    "    'ground':   {'fire': 2, 'electric': 2, 'poison': 2, 'rock': 2, 'grass': 0.5, 'flying': 0},\n",
    "    'flying':   {'grass': 2, 'fighting': 2, 'bug': 2, 'rock': 0.5, 'electric': 0.5},\n",
    "    'psychic':  {'poison': 2, 'fighting': 2, 'psychic': 0.5},\n",
    "    'bug':      {'grass': 2, 'psychic': 2, 'poison': 0.5, 'fire': 0.5, 'flying': 0.5},\n",
    "    'rock':     {'fire': 2, 'ice': 2, 'flying': 2, 'bug': 2, 'ground': 0.5},\n",
    "    'ghost':    {'ghost': 2, 'psychic': 0},\n",
    "    'dragon':   {'dragon': 2},\n",
    "    'notype':   {}\n",
    "}\n",
    "\n",
    "# Given two types, we turn the type-chart into a simple score:\n",
    "#   +1  if attacking_type is super effective vs defending_type\n",
    "#   -1  if it is not very effective\n",
    "#   -2  if it does no damage (immune)\n",
    "#    0  if it is neutral.\n",
    "\n",
    "def type_match(attacking_type, defending_type):\n",
    "    v = effectiveness.get(attacking_type, {}).get(defending_type, 1)\n",
    "    if v == 0:\n",
    "        return -2\n",
    "    if v < 1:\n",
    "        return -1\n",
    "    if v > 1:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# =========================\n",
    "# Status severity mapping (since pokemon status is a string, here we are mapping it to numeric).\n",
    "# The bigger the number, the \"worse\" the status.\n",
    "#\n",
    "# - 0 = no status or faint (we treat faint separately in other logic)\n",
    "# - 1 = mild status (paralysis, burn, poison)\n",
    "# - 2 = severe (toxic, freeze)\n",
    "# - 3 = sleep (very strong in Gen 1)\n",
    "#\n",
    "# The following table may have been taken from internet, formatted as below and \n",
    "# copy pasted here.\n",
    "# =========================\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "MAP_STATUS = {'nostatus':0,'par':1,'brn':1,'psn':1,'tox':2,'frz':2,'slp':3,'fnt':0}\n",
    "\n",
    "# Sets of move names for special categories:\n",
    "RECOVERY_MOVES = {'recover','softboiled','rest'}\n",
    "HIGH_CRIT      = {'slash','crabhammer','razorleaf','karatechop'}\n",
    "TRAPS          = {'wrap','clamp','firespin'}\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# MAIN FEATURE GENERATOR\n",
    "# ------------------------------------------------------------\n",
    "# This is the main feature function.\n",
    "# It takes the raw list of battles and, for each battle, builds a big\n",
    "# dictionary of numeric features. Then it returns a DataFrame with one\n",
    "# row per battle and one column per feature (plus battle_id and player_won).\n",
    "# ------------------------------------------------------------\n",
    "# This is the main feature function.\n",
    "# It takes the raw list of battles and, for each battle, builds a big\n",
    "# dictionary of numeric features. Then it returns a DataFrame with one\n",
    "# row per battle and one column per feature (plus battle_id and player_won).\n",
    "def build_features(dataset):\n",
    "    \"\"\"\n",
    "    Build the full feature set from the raw battle logs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : list[dict]\n",
    "        Raw battles from train.jsonl or test.jsonl. Each battle is a dict\n",
    "        containing at least:\n",
    "          - 'battle_id'\n",
    "          - 'battle_timeline' (list of turns; each turn has p1/p2 states and moves)\n",
    "          - 'player_won' (only in train)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        One row per battle, with:\n",
    "          - all features (engineered below)\n",
    "          - 'battle_id'\n",
    "          - 'player_won' (only for train).\n",
    "\n",
    "    General convention\n",
    "    ------------------\n",
    "    Almost all features are defined as a *difference* between player 2 and\n",
    "    player 1 or between (p1 - p2). The sign tells us who is advantaged:\n",
    "      - Positive value for a \"p2 - p1\" feature  -> advantage for player 2\n",
    "      - Negative value for a \"p2 - p1\" feature  -> advantage for player 1\n",
    "      - Positive value for a \"p1 - p2\" feature  -> advantage for player 1\n",
    "    \"\"\"\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # We loop over each battle in the dataset\n",
    "    for battle in tqdm(dataset, desc=\"Building features\"):\n",
    "        # feats will be a dictionary: key = feature name, value = number\n",
    "        feats = {}\n",
    "\n",
    "        # Get the timeline: list of turns (each is a dict with states + moves)\n",
    "        timeline = battle.get('battle_timeline', []) or []\n",
    "        den = len(timeline)  # number of turns in the battle\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Basic sequences that we extract from the timeline\n",
    "        # - p1n / p2n: active Pokémon name each turn\n",
    "        # - p1s / p2s: status of the active Pokémon each turn\n",
    "        # - p1hp / p2hp: HP% of the active Pokémon each turn\n",
    "        # - md1 / md2: move details used each turn by each player\n",
    "        # - eff1 / eff2: set of \"effects\" currently active (substitute, reflect...)\n",
    "        # These sequences are the raw material for most of the features below.\n",
    "        # --------------------------------------------------------\n",
    "        p1n = [str(t['p1_pokemon_state'].get('name','')).lower() for t in timeline] if den else []\n",
    "        p2n = [str(t['p2_pokemon_state'].get('name','')).lower() for t in timeline] if den else []\n",
    "        p1s = [str(t['p1_pokemon_state'].get('status','nostatus')).lower() for t in timeline] if den else []\n",
    "        p2s = [str(t['p2_pokemon_state'].get('status','nostatus')).lower() for t in timeline] if den else []\n",
    "        p1hp = [float(t['p1_pokemon_state'].get('hp_pct',0.0)) for t in timeline] if den else []\n",
    "        p2hp = [float(t['p2_pokemon_state'].get('hp_pct',0.0)) for t in timeline] if den else []\n",
    "        md1 = [(t.get('p1_move_details') or {}) for t in timeline] if den else []\n",
    "        md2 = [(t.get('p2_move_details') or {}) for t in timeline] if den else []\n",
    "        eff1 = [set(t['p1_pokemon_state'].get('effects') or []) for t in timeline] if den else []\n",
    "        eff2 = [set(t['p2_pokemon_state'].get('effects') or []) for t in timeline] if den else []\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Final HP and final status per species (for both players)\n",
    "        # We keep track of the last HP and last status seen for each species.\n",
    "        # These are then used to build \"end-of-battle\" features.\n",
    "        # --------------------------------------------------------\n",
    "        hp_last_p1, hp_last_p2 = {}, {}\n",
    "        st_last_p1, st_last_p2 = {}, {}\n",
    "        for t in timeline:\n",
    "            n1 = str(t['p1_pokemon_state'].get('name','')).lower()\n",
    "            n2 = str(t['p2_pokemon_state'].get('name','')).lower()\n",
    "            hp_last_p1[n1] = float(t['p1_pokemon_state'].get('hp_pct',0.0))\n",
    "            hp_last_p2[n2] = float(t['p2_pokemon_state'].get('hp_pct',0.0))\n",
    "            st_last_p1[n1] = str(t['p1_pokemon_state'].get('status','nostatus')).lower()\n",
    "            st_last_p2[n2] = str(t['p2_pokemon_state'].get('status','nostatus')).lower()\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # hp_edge_final:\n",
    "        #   FINAL HP edge = (mean HP of player 2 team) - (mean HP of player 1 team)\n",
    "        #   > 0 : on average p2's remaining mons are healthier at the end\n",
    "        #   < 0 : advantage in HP for p1 at the end\n",
    "        # --------------------------------------------------------\n",
    "        mean_hp_p1 = float(np.mean(list(hp_last_p1.values()))) if hp_last_p1 else 0.0\n",
    "        mean_hp_p2 = float(np.mean(list(hp_last_p2.values()))) if hp_last_p2 else 0.0\n",
    "        feats['hp_edge_final'] = float(mean_hp_p2 - mean_hp_p1)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p1_alive_final:\n",
    "        #   Number of p1 Pokémon that still have hp > 0 at the end.\n",
    "        #   Rough proxy for how many \"resources\" remain for p1.\n",
    "        # --------------------------------------------------------\n",
    "        feats['p1_alive_final'] = int(sum(hp > 0 for hp in hp_last_p1.values()))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p1_status_mean_final:\n",
    "        #   Average status severity over p1's team at the end.\n",
    "        #\n",
    "        # status_severity_gap_final:\n",
    "        #   FINAL status severity difference = (p2 mean severity) - (p1 mean severity)\n",
    "        #   If status_severity_gap_final > 0: p2 is \"worse off\" in terms of status than p1.\n",
    "        # --------------------------------------------------------\n",
    "        p1_status_mean_final = float(np.mean([MAP_STATUS.get(s,0) for s in st_last_p1.values()])) if st_last_p1 else 0.0\n",
    "        p2_status_mean_final = float(np.mean([MAP_STATUS.get(s,0) for s in st_last_p2.values()])) if st_last_p2 else 0.0\n",
    "        feats['p1_status_mean_final'] = p1_status_mean_final\n",
    "        feats['status_severity_gap_final'] = float(p2_status_mean_final - p1_status_mean_final)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # revealed_count_diff:\n",
    "        #   (# of distinct species that appeared on the field for p1)\n",
    "        # - (# of distinct species that appeared on the field for p2).\n",
    "        #   Positive: p1 revealed more different Pokémon than p2.\n",
    "        # --------------------------------------------------------\n",
    "        revealed_p1 = set(p1n)\n",
    "        revealed_p2 = set(p2n)\n",
    "        feats['revealed_count_diff'] = int(len(revealed_p1) - len(revealed_p2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # status_turns_advantage:\n",
    "        #   Sum over turns of (status severity for p1 - status severity for p2).\n",
    "        #   Positive: across the whole battle p1 suffered \"worse\" status conditions\n",
    "        #   for more turns than p2.\n",
    "        # --------------------------------------------------------\n",
    "        p1_status_series = [MAP_STATUS.get(s,0) for s in p1s]\n",
    "        p2_status_series = [MAP_STATUS.get(s,0) for s in p2s]\n",
    "        feats['status_turns_advantage'] = int(sum(p1_status_series) - sum(p2_status_series))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # tox_ratio_diff:\n",
    "        #   For each player we look at all poison-related turns and compute:\n",
    "        #      tox_ratio = (# toxic turns) / (# poison+toxic turns)\n",
    "        #   Then tox_ratio_diff = (p1 tox_ratio - p2 tox_ratio).\n",
    "        #   Positive: p1 is \"more often\" under severe toxic than normal poison,\n",
    "        #   relative to p2.\n",
    "        # --------------------------------------------------------\n",
    "        p1_psn_cnt = sum(1 for s in p1s if s in {'psn','tox'})\n",
    "        p2_psn_cnt = sum(1 for s in p2s if s in {'psn','tox'})\n",
    "        p1_tox_cnt = sum(1 for s in p1s if s == 'tox')\n",
    "        p2_tox_cnt = sum(1 for s in p2s if s == 'tox')\n",
    "        p1_tox_ratio = (p1_tox_cnt / p1_psn_cnt) if p1_psn_cnt else 0.0\n",
    "        p2_tox_ratio = (p2_tox_cnt / p2_psn_cnt) if p2_psn_cnt else 0.0\n",
    "        feats['tox_ratio_diff'] = float(p1_tox_ratio - p2_tox_ratio)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # HP gap across time (per turn)\n",
    "        # hp_gap[t] = p2_hp[t] - p1_hp[t]\n",
    "        #   > 0 : p2 is overall ahead in HP at that turn\n",
    "        #   < 0 : p1 is ahead\n",
    "        # --------------------------------------------------------\n",
    "        hp_gap = (np.array(p2hp) - np.array(p1hp)) if den else np.array([])\n",
    "\n",
    "        # We split the battle into thirds (early, mid, late) based on number of turns.\n",
    "        E = max(1, den//3) if den else 1\n",
    "        mid_start, mid_end = E, max(E*2, min(den, E*2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Helper to find switch indices (turns when the active mon changes)\n",
    "        # --------------------------------------------------------\n",
    "        def switches(seq):\n",
    "            idx = []\n",
    "            for i in range(1, len(seq)):\n",
    "                if seq[i] != seq[i-1]:\n",
    "                    idx.append(i)\n",
    "            return idx\n",
    "\n",
    "        # sw1/sw2: indices of player 1 and 2 switches.\n",
    "        sw1 = switches(p1n) if den else []\n",
    "        sw2 = switches(p2n) if den else []\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # forced_switch_share_diff:\n",
    "        #   We call a switch \"forced\" if, right after the switch, the HP gap\n",
    "        #   moves in the direction suggesting a bad position:\n",
    "        #     - For p1: hp_gap[i] - hp_gap[i-1] > 0  (gap moves towards p2)\n",
    "        #     - For p2: hp_gap[i] - hp_gap[i-1] < 0  (gap moves towards p1)\n",
    "        #\n",
    "        #   forced_switch_share_diff = (forced switches share for p2) -\n",
    "        #                              (forced switches share for p1)\n",
    "        #   Positive: p2 is more often switching from a worse position.\n",
    "        # --------------------------------------------------------\n",
    "        forced_p1 = 0\n",
    "        forced_p2 = 0\n",
    "        if den and len(hp_gap) > 1:\n",
    "            for i in sw1:\n",
    "                if i-1 >= 0 and float(hp_gap[i] - hp_gap[i-1]) > 0:\n",
    "                    forced_p1 += 1\n",
    "            for i in sw2:\n",
    "                if i-1 >= 0 and float(hp_gap[i] - hp_gap[i-1]) < 0:\n",
    "                    forced_p2 += 1\n",
    "        p1_forced_share = (forced_p1 / len(sw1)) if sw1 else 0.0\n",
    "        p2_forced_share = (forced_p2 / len(sw2)) if sw2 else 0.0\n",
    "        feats['forced_switch_share_diff'] = float(p2_forced_share - p1_forced_share)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # active_entropy_diff:\n",
    "        #   Entropy of the active Pokémon usage distribution for each player.\n",
    "        #   High entropy -> many different mons used in a balanced way.\n",
    "        #   active_entropy_diff = H(p1_active) - H(p2_active)\n",
    "        #   Positive: p1's usage is more diverse than p2's.\n",
    "        # --------------------------------------------------------\n",
    "        def entropy(counter):\n",
    "            tot = float(sum(counter.values()))\n",
    "            if tot <= 0: return 0.0\n",
    "            p = [c/tot for c in counter.values()]\n",
    "            return float(-sum(pi*np.log(max(pi,1e-12)) for pi in p))\n",
    "\n",
    "        c1 = Counter(p1n); c2 = Counter(p2n)\n",
    "        feats['active_entropy_diff'] = float(entropy(c1) - entropy(c2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Damage and healing sequences:\n",
    "        # p1_loss / p2_loss: HP lost per turn (strictly positive when HP decreases)\n",
    "        # p1_heal / p2_heal: HP recovered per turn (strictly positive when HP increases)\n",
    "        # These support damage/healing related features.\n",
    "        # --------------------------------------------------------\n",
    "        p1_loss = [max(0.0, p1hp[i-1]-p1hp[i]) for i in range(1, den)] if den>1 else []\n",
    "        p2_loss = [max(0.0, p2hp[i-1]-p2hp[i]) for i in range(1, den)] if den>1 else []\n",
    "        p1_heal = [max(0.0, p1hp[i]-p1hp[i-1]) for i in range(1, den)] if den>1 else []\n",
    "        p2_heal = [max(0.0, p2hp[i]-p2hp[i-1]) for i in range(1, den)] if den>1 else []\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p2_late_damage:\n",
    "        #   Total HP lost by p2 in the late third of the game.\n",
    "        #   High values: p2 is taking a lot of damage late-game.\n",
    "        # --------------------------------------------------------\n",
    "        feats['p2_late_damage'] = float(sum(p2_loss[-E:]) if p2_loss else 0.0)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # attacks_rate_diff:\n",
    "        #   (p1 attacks per turn) - (p2 attacks per turn).\n",
    "        #   Here an \"attack\" is any turn where the move has a non-empty name.\n",
    "        #   Positive: p1 is clicking more moves per turn than p2.\n",
    "        # --------------------------------------------------------\n",
    "        p1_attacks = sum(1 for m in md1 if m.get('name'))\n",
    "        p2_attacks = sum(1 for m in md2 if m.get('name'))\n",
    "        feats['attacks_rate_diff'] = float((p1_attacks / den if den else 0.0) - (p2_attacks / den if den else 0.0))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # bp_mean_p2:\n",
    "        #   Average base power of moves used by p2 (only non-null moves).\n",
    "        #   Rough proxy for how \"strong\" p2's typical move is.\n",
    "        # --------------------------------------------------------\n",
    "        feats['bp_mean_p2'] = float(\n",
    "            np.mean([float(m.get('base_power',0.0)) for m in md2\n",
    "                     if m.get('name') and m.get('base_power') is not None]) if p2_attacks else 0.0\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # HP-based global features:\n",
    "        #   hp_gap_peak           : max(hp_gap[t]) = best HP advantage for p2\n",
    "        #   hp_gap_peak_turn_share: (turn index of that peak + 1) / total_turns\n",
    "        #                            (where in the battle that best moment happens)\n",
    "        #   hp_gap_var            : variance of hp_gap across the battle\n",
    "        #   hp_gap_autocorr       : correlation between hp_gap[t] and hp_gap[t+1]\n",
    "        #                           (how persistent the advantage is from turn to turn)\n",
    "        #   hp_gap_sign_flips     : number of times the sign of hp_gap changes\n",
    "        #                           (how often the lead changes between players)\n",
    "        # --------------------------------------------------------\n",
    "        if den and len(hp_gap):\n",
    "            feats['hp_gap_peak'] = float(np.max(hp_gap))\n",
    "            feats['hp_gap_peak_turn_share'] = float((int(np.argmax(hp_gap))+1) / den)\n",
    "            feats['hp_gap_var'] = float(np.var(hp_gap))\n",
    "\n",
    "            if len(hp_gap) >= 2 and np.var(hp_gap)>0 and np.var(hp_gap[:-1])>0 and np.var(hp_gap[1:])>0:\n",
    "                feats['hp_gap_autocorr'] = float(np.corrcoef(hp_gap[:-1], hp_gap[1:])[0,1])\n",
    "            else:\n",
    "                feats['hp_gap_autocorr'] = 0.0\n",
    "\n",
    "            sgn = np.sign(hp_gap)\n",
    "            feats['hp_gap_sign_flips'] = int(\n",
    "                sum(1 for a,b in zip(sgn, sgn[1:])\n",
    "                    if a!=0 and b!=0 and a!=b)\n",
    "            )\n",
    "        else:\n",
    "            feats['hp_gap_peak'] = 0.0\n",
    "            feats['hp_gap_peak_turn_share'] = 0.0\n",
    "            feats['hp_gap_var'] = 0.0\n",
    "            feats['hp_gap_autocorr'] = 0.0\n",
    "            feats['hp_gap_sign_flips'] = 0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # lead_type_edge:\n",
    "        #   Type matchup edge of the lead (turn 1) position:\n",
    "        #   we compute how much p2's lead types are good vs p1's lead types,\n",
    "        #   minus how much p1's lead types are good vs p2's.\n",
    "        #\n",
    "        # lead_def_edge:\n",
    "        #   Base Defense stat difference of the leads = (p2_def - p1_def).\n",
    "        # --------------------------------------------------------\n",
    "        if den:\n",
    "            lead1 = p1n[0]; lead2 = p2n[0]\n",
    "            t1 = [t for t in types_map.get(lead1, [\"notype\",\"notype\"]) if t!='notype']\n",
    "            t2 = [t for t in types_map.get(lead2, [\"notype\",\"notype\"]) if t!='notype']\n",
    "            lead_edge = 0\n",
    "            for a in t2:\n",
    "                for b in t1:\n",
    "                    lead_edge += type_match(a,b)\n",
    "                    lead_edge -= type_match(b,a)\n",
    "            feats['lead_type_edge'] = int(lead_edge)\n",
    "\n",
    "            d1 = species.get(lead1,{}).get('def',0); d2 = species.get(lead2,{}).get('def',0)\n",
    "            feats['lead_def_edge'] = float(d2 - d1)\n",
    "        else:\n",
    "            feats['lead_type_edge'] = 0\n",
    "            feats['lead_def_edge'] = 0.0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # types_last_round:\n",
    "        #   Type edge at the very last turn based on the last two active Pokémon:\n",
    "        #       sum(type_match(p1_type, p2_type)) - sum(type_match(p2_type, p1_type))\n",
    "        #   Positive: final board position is type-favorable to p1.\n",
    "        # --------------------------------------------------------\n",
    "        if den:\n",
    "            last1 = p1n[-1]; last2 = p2n[-1]\n",
    "            tp1 = types_map.get(last1, [\"notype\",\"notype\"])\n",
    "            tp2 = types_map.get(last2, [\"notype\",\"notype\"])\n",
    "            scf = 0\n",
    "            for a in tp1:\n",
    "                for b in tp2:\n",
    "                    scf += type_match(a,b)\n",
    "                    scf -= type_match(b,a)\n",
    "            feats['types_last_round'] = int(scf)\n",
    "        else:\n",
    "            feats['types_last_round'] = 0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # rs_hit_share_diff:\n",
    "        #   For each player, we count hits that are:\n",
    "        #     - super effective (se)\n",
    "        #     - resisted (rs)\n",
    "        #     - immune (im)\n",
    "        #   rs_hit_share_diff = (resisted hits share for p1) - (resisted hits share for p2).\n",
    "        #\n",
    "        # immune_count_diff:\n",
    "        #   (number of times p1 hits into an immunity) - (number of times p2 does).\n",
    "        #\n",
    "        # p1_immune_count:\n",
    "        #   Raw count of p1's hits into immunity.\n",
    "        # --------------------------------------------------------\n",
    "        se1=rs1=im1=act1=0\n",
    "        se2=rs2=im2=act2=0\n",
    "        for i in range(den):\n",
    "            m1 = md1[i]; m2 = md2[i]\n",
    "            if m1.get('name'):\n",
    "                mv_t = str(m1.get('type','') or '').lower()\n",
    "                if mv_t:\n",
    "                    on = p2n[i] if i < len(p2n) else ''\n",
    "                    for ot in [x for x in types_map.get(on, [\"notype\",\"notype\"]) if x!='notype']:\n",
    "                        v = type_match(mv_t, ot)\n",
    "                        if v > 0: se1 += 1\n",
    "                        elif v < 0 and v != -2: rs1 += 1\n",
    "                        elif v == -2: im1 += 1\n",
    "                    act1 += 1\n",
    "            if m2.get('name'):\n",
    "                mv_t = str(m2.get('type','') or '').lower()\n",
    "                if mv_t:\n",
    "                    on = p1n[i] if i < len(p1n) else ''\n",
    "                    for ot in [x for x in types_map.get(on, [\"notype\",\"notype\"]) if x!='notype']:\n",
    "                        v = type_match(mv_t, ot)\n",
    "                        if v > 0: se2 += 1\n",
    "                        elif v < 0 and v != -2: rs2 += 1\n",
    "                        elif v == -2: im2 += 1\n",
    "                    act2 += 1\n",
    "        rs_share1 = (rs1/act1) if act1 else 0.0\n",
    "        rs_share2 = (rs2/act2) if act2 else 0.0\n",
    "        feats['rs_hit_share_diff'] = float(rs_share1 - rs_share2)\n",
    "        feats['p1_immune_count'] = int(im1)\n",
    "        feats['immune_count_diff'] = int((im1) - (im2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # boom_count_diff:\n",
    "        #   (# of boom moves used by p1) - (# used by p2),\n",
    "        #   where boom moves are Explosion / Selfdestruct.\n",
    "        #   Positive: p1 uses more self-sacrificing moves.\n",
    "        # --------------------------------------------------------\n",
    "        feats['boom_count_diff'] = int(\n",
    "            sum(1 for m in md1 if str(m.get('name','')).lower() in {'explosion','selfdestruct'})\n",
    "            - sum(1 for m in md2 if str(m.get('name','')).lower() in {'explosion','selfdestruct'})\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # counter_count_diff:\n",
    "        #   (# of \"Counter\" uses by p1) - (# by p2).\n",
    "        # --------------------------------------------------------\n",
    "        feats['counter_count_diff'] = int(\n",
    "            sum(1 for m in md1 if str(m.get('name','')).lower()=='counter')\n",
    "            - sum(1 for m in md2 if str(m.get('name','')).lower()=='counter')\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # move_diversity_p1:\n",
    "        #   Number of distinct moves used by p1 in the battle.\n",
    "        #   Measures how many different tools p1 actually clicked.\n",
    "        # --------------------------------------------------------\n",
    "        feats['move_diversity_p1'] = int(len({str(m.get('name')) for m in md1 if m.get('name')}))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Usage-weighted base stats:\n",
    "        # c1 / c2 count how many turns each species was active for p1/p2.\n",
    "        # wmean(counter, key): weighted average of a base stat (key) over the\n",
    "        #                      mons in the counter, using \"# of turns on field\" as weights.\n",
    "        # --------------------------------------------------------\n",
    "        c1 = Counter(p1n); c2 = Counter(p2n)\n",
    "        def wmean(counter, key):\n",
    "            S = 0.0; W = 0.0\n",
    "            for nm,w in counter.items():\n",
    "                if nm in species:\n",
    "                    S += float(species[nm].get(key,0)) * w\n",
    "                    W += w\n",
    "            return (S/W) if W else 0.0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # used_mean_spe_diff:\n",
    "        #   (avg speed of Pokémon used by p1, weighted by turns on field)\n",
    "        # - (avg speed of Pokémon used by p2, weighted by turns on field).\n",
    "        #   Positive: p1 tends to have faster mons on the field.\n",
    "        #\n",
    "        # p2_used_count:\n",
    "        #   Number of distinct Pokémon that p2 actually used (took the field).\n",
    "        # --------------------------------------------------------\n",
    "        p1_mean_spe_used = wmean(c1,'spe')\n",
    "        p2_mean_spe_used = wmean(c2,'spe')\n",
    "        feats['used_mean_spe_diff'] = float(p1_mean_spe_used - p2_mean_spe_used)\n",
    "        feats['p2_used_count'] = int(len(c2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # eff_speed_adv_share_p2 / eff_speed_edge_avg:\n",
    "        #   We compute \"effective speed\" each turn combining:\n",
    "        #     - base speed\n",
    "        #     - speed boosts (Gen 1 style multipliers)\n",
    "        #     - paralysis modifier (0.25 if PAR)\n",
    "        #\n",
    "        #   eff_speed_adv_share_p2:\n",
    "        #       share of turns where p2 effective speed >= p1 effective speed.\n",
    "        #\n",
    "        #   eff_speed_edge_avg:\n",
    "        #       average (p2_effective_speed - p1_effective_speed) over all turns.\n",
    "        # --------------------------------------------------------\n",
    "        eff_adv = 0\n",
    "        edge_sum = 0.0\n",
    "        for i in range(den):\n",
    "            s1 = timeline[i]['p1_pokemon_state']; s2 = timeline[i]['p2_pokemon_state']\n",
    "            n1 = str(s1.get('name','')).lower(); n2 = str(s2.get('name','')).lower()\n",
    "            base1 = species.get(n1,{})\n",
    "            base2 = species.get(n2,{})\n",
    "            b1 = (s1.get('boosts') or {})\n",
    "            b2 = (s2.get('boosts') or {})\n",
    "\n",
    "            # Effective speed = base_speed * boost_multiplier\n",
    "            try:\n",
    "                sp1 = float(base1.get('spe',0)) * (\n",
    "                    (2.0 + int(b1.get('spe',0)))/2.0 if int(b1.get('spe',0))>=0\n",
    "                    else 2.0/(2.0-int(b1.get('spe',0)))\n",
    "                )\n",
    "            except:\n",
    "                sp1 = float(base1.get('spe',0))\n",
    "            try:\n",
    "                sp2 = float(base2.get('spe',0)) * (\n",
    "                    (2.0 + int(b2.get('spe',0)))/2.0 if int(b2.get('spe',0))>=0\n",
    "                    else 2.0/(2.0-int(b2.get('spe',0)))\n",
    "                )\n",
    "            except:\n",
    "                sp2 = float(base2.get('spe',0))\n",
    "\n",
    "            # Paralysis penalty\n",
    "            if str(s1.get('status','')).lower()=='par': sp1 *= 0.25\n",
    "            if str(s2.get('status','')).lower()=='par': sp2 *= 0.25\n",
    "\n",
    "            # p2 is faster or equal\n",
    "            if sp2 >= sp1: eff_adv += 1\n",
    "            edge_sum += (sp2 - sp1)\n",
    "\n",
    "        feats['eff_speed_adv_share_p2'] = float((eff_adv/den) if den else 0.0)\n",
    "        feats['eff_speed_edge_avg'] = float((edge_sum/den) if den else 0.0)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # initiative_early_diff / initiative_late_diff:\n",
    "        #   For early turns and late turns separately, we look at\n",
    "        #   how often p1's base speed >= p2's base speed.\n",
    "        #\n",
    "        #   For a window [start,end):\n",
    "        #     - let f = # of turns where p1 base speed >= p2 base speed\n",
    "        #     - L = length of the window\n",
    "        #     - share_for_p1 = f/L\n",
    "        #     - share_for_p2 = (L-f)/L\n",
    "        #   init_share = share_for_p1 - share_for_p2.\n",
    "        #\n",
    "        #   initiative_early_diff = init_share in the early third of the battle\n",
    "        #   initiative_late_diff  = init_share in the final third of the battle\n",
    "        # --------------------------------------------------------\n",
    "        def init_share(seq_len, start, end):\n",
    "            if end <= start or den==0: return 0.0\n",
    "            f = 0\n",
    "            for i in range(start, end):\n",
    "                if i >= den: break\n",
    "                n1 = p1n[i] if i < len(p1n) else ''\n",
    "                n2 = p2n[i] if i < len(p2n) else ''\n",
    "                s1 = species.get(n1,{}).get('spe',0)\n",
    "                s2 = species.get(n2,{}).get('spe',0)\n",
    "                if s1 >= s2: f += 1\n",
    "            L = max(1, end-start)\n",
    "            return float(f/L) - float((L-f)/L)\n",
    "\n",
    "        feats['initiative_early_diff'] = float(init_share(den, 0, min(E, den)))\n",
    "        feats['initiative_late_diff']  = float(init_share(den, max(0, den-E), den))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # last_switch_turn_p1:\n",
    "        #   Last turn index (1-based) on which p1 changes the active Pokémon.\n",
    "        #   If p1 never switches, we set it to den+1 (a \"virtual\" late switch).\n",
    "        # --------------------------------------------------------\n",
    "        last_sw = 0\n",
    "        for i in range(1, den):\n",
    "            if p1n[i] != p1n[i-1]:\n",
    "                last_sw = i+1\n",
    "        feats['last_switch_turn_p1'] = int(last_sw if last_sw else den+1)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Ping-pong switching patterns:\n",
    "        #   Recurring pattern A -> B -> A (returns to the same mon after\n",
    "        #   exactly one different mon).\n",
    "        #\n",
    "        # p1_pingpong_switches:\n",
    "        #   Number of ping-pong patterns for p1.\n",
    "        #\n",
    "        # pingpong_switches_diff:\n",
    "        #   p1_pingpong_switches - p2_pingpong_switches.\n",
    "        # --------------------------------------------------------\n",
    "        def pingpong(seq):\n",
    "            c = 0\n",
    "            for i in range(2, len(seq)):\n",
    "                if seq[i]==seq[i-2] and seq[i]!=seq[i-1]:\n",
    "                    c += 1\n",
    "            return c\n",
    "\n",
    "        feats['p1_pingpong_switches'] = int(pingpong(p1n))\n",
    "        feats['pingpong_switches_diff'] = int(pingpong(p1n) - pingpong(p2n))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # both_switched_share:\n",
    "        #   Share of turns (from turn 2 onward) where BOTH players switch\n",
    "        #   between turn i-1 and i.\n",
    "        # --------------------------------------------------------\n",
    "        both_sw = 0\n",
    "        for i in range(1, den):\n",
    "            if p1n[i]!=p1n[i-1] and p2n[i]!=p2n[i-1]:\n",
    "                both_sw += 1\n",
    "        feats['both_switched_share'] = float(both_sw / max(1, (den-1)))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p1_switch_late_share:\n",
    "        #   Among the last third of turns, how many are p1 switch turns,\n",
    "        #   normalized by the number of turns in that late window.\n",
    "        #   Measures how much p1 is \"shuffling\" late-game.\n",
    "        # --------------------------------------------------------\n",
    "        late_sw1 = 0\n",
    "        for i in range(max(1, den-E), den):\n",
    "            if i < len(p1n) and i-1 >= 0 and p1n[i] != p1n[i-1]:\n",
    "                late_sw1 += 1\n",
    "        feats['p1_switch_late_share'] = float(late_sw1 / max(1, min(E, den-1)))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # severe_status_early_share:\n",
    "        #   Share of early turns where at least one side has a status of\n",
    "        #   severity >= 2 (e.g. serious conditions like sleep, freeze,\n",
    "        #   badly poisoned, depending on MAP_STATUS).\n",
    "        #   It ignores which side, only checks \"does somebody suffer a bad status?\".\n",
    "        # --------------------------------------------------------\n",
    "        severe = [(a>=2 or b>=2) for a,b in zip(p1_status_series, p2_status_series)]\n",
    "        feats['severe_status_early_share'] = float(\n",
    "            sum(1 for x in severe[:E] if x) / max(1,E)\n",
    "        ) if den else 0.0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # status_diversity_p1:\n",
    "        #   Number of different non-\"nostatus\" statuses p1 has experienced.\n",
    "        #\n",
    "        # status_diversity_diff:\n",
    "        #   status_diversity_p1 - status_diversity_p2.\n",
    "        # --------------------------------------------------------\n",
    "        sd1 = len({s for s in p1s if s!='nostatus'})\n",
    "        sd2 = len({s for s in p2s if s!='nostatus'})\n",
    "        feats['status_diversity_p1'] = int(sd1)\n",
    "        feats['status_diversity_diff'] = int(sd1 - sd2)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # status_late_share_diff:\n",
    "        #   In the late third of the battle, we compute:\n",
    "        #       share of STATUS-category moves for p2\n",
    "        #     - share of STATUS-category moves for p1\n",
    "        #   Positive: p2 is using relatively more status moves late-game.\n",
    "        # --------------------------------------------------------\n",
    "        def share_status_late(md):\n",
    "            late = md[max(0, den-E):den]\n",
    "            tot = sum(1 for m in late if m.get('name'))\n",
    "            sts = sum(1 for m in late if str(m.get('category','')).upper()=='STATUS' and m.get('name'))\n",
    "            return (sts/tot) if tot else 0.0\n",
    "\n",
    "        feats['status_late_share_diff'] = float(share_status_late(md2) - share_status_late(md1))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # rec_share_diff:\n",
    "        #   share of recovery moves used by p1 minus share of recovery moves used by p2.\n",
    "        #   \"Recovery\" moves are taken from the RECOVERY_MOVES list.\n",
    "        # --------------------------------------------------------\n",
    "        def rec_share(md):\n",
    "            tot = sum(1 for m in md if m.get('name'))\n",
    "            rec = sum(1 for m in md if str(m.get('name','')).lower() in RECOVERY_MOVES)\n",
    "            return (rec/tot) if tot else 0.0\n",
    "\n",
    "        feats['rec_share_diff'] = float(rec_share(md1) - rec_share(md2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # same_move_streak_max_diff:\n",
    "        #   For each player we compute the longest streak of repeating the same\n",
    "        #   move (same name) on consecutive turns. Then:\n",
    "        #     same_move_streak_max_diff = max_streak_p1 - max_streak_p2\n",
    "        #   Positive: p1 \"spams\" the same move more than p2.\n",
    "        # --------------------------------------------------------\n",
    "        def same_move_streak_max(md):\n",
    "            best=cur=0; prev=None\n",
    "            for m in md:\n",
    "                nm = str(m.get('name','')).lower() if m.get('name') else None\n",
    "                if not nm:\n",
    "                    cur = 0; prev = None\n",
    "                else:\n",
    "                    if nm==prev: cur += 1\n",
    "                    else: cur = 1\n",
    "                    best = max(best, cur); prev = nm\n",
    "            return best\n",
    "\n",
    "        feats['same_move_streak_max_diff'] = int(same_move_streak_max(md1) - same_move_streak_max(md2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # confusion_late_share_diff:\n",
    "        #   In the late third, share of turns where p1 is confused minus\n",
    "        #   share of turns where p2 is confused.\n",
    "        #\n",
    "        # substitute_late_share_diff:\n",
    "        #   In the late third, share of turns where p1 has Substitute active\n",
    "        #   minus share where p2 has Substitute.\n",
    "        #\n",
    "        # reflect_early_share_diff:\n",
    "        #   In the early third, share of turns where p1 has Reflect active\n",
    "        #   minus share where p2 has Reflect.\n",
    "        # --------------------------------------------------------\n",
    "        def eff_share(eff, tag, slc):\n",
    "            seg = eff[slc]\n",
    "            return float(sum(1 for s in seg if tag in s) / max(1, len(seg))) if den else 0.0\n",
    "\n",
    "        early_slice = slice(0, min(E, den))\n",
    "        late_slice  = slice(max(0, den-E), den)\n",
    "        feats['confusion_late_share_diff'] = float(\n",
    "            eff_share(eff1,'confusion', late_slice) - eff_share(eff2,'confusion', late_slice)\n",
    "        )\n",
    "        feats['substitute_late_share_diff'] = float(\n",
    "            eff_share(eff1,'substitute', late_slice) - eff_share(eff2,'substitute', late_slice)\n",
    "        )\n",
    "        feats['reflect_early_share_diff'] = float(\n",
    "            eff_share(eff1,'reflect', early_slice) - eff_share(eff2,'reflect', early_slice)\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # confusion_turns_diff:\n",
    "        #   (# of turns p1 is under confusion) - (# of turns p2 is under confusion).\n",
    "        # --------------------------------------------------------\n",
    "        feats['confusion_turns_diff'] = int(\n",
    "            sum(1 for s in eff1 if 'confusion' in s) - sum(1 for s in eff2 if 'confusion' in s)\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p1_sleep_streak_max:\n",
    "        #   Longest consecutive number of turns where p1 is sleeping.\n",
    "        #\n",
    "        # sleep_streak_max_diff:\n",
    "        #   p1_sleep_streak_max - p2_sleep_streak_max.\n",
    "        # --------------------------------------------------------\n",
    "        def max_streak(seq, tag):\n",
    "            b=0; c=0\n",
    "            for s in seq:\n",
    "                if s==tag: c+=1; b=max(b,c)\n",
    "                else: c=0\n",
    "            return b\n",
    "\n",
    "        feats['p1_sleep_streak_max'] = int(max_streak(p1s,'slp'))\n",
    "        feats['sleep_streak_max_diff'] = int(max_streak(p1s,'slp') - max_streak(p2s,'slp'))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p1_turns_par:\n",
    "        #   Total number of turns where p1 is paralyzed.\n",
    "        #\n",
    "        # p2_turns_brn:\n",
    "        #   Total number of turns where p2 is burned.\n",
    "        # --------------------------------------------------------\n",
    "        feats['p1_turns_par'] = int(sum(1 for s in p1s if s=='par'))\n",
    "        feats['p2_turns_brn'] = int(sum(1 for s in p2s if s=='brn'))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Type coverage / diversity:\n",
    "        #\n",
    "        # seen_types(names):\n",
    "        #   Set of types seen on the field for the given list of Pokémon names.\n",
    "        #\n",
    "        # type_seen_count_diff:\n",
    "        #   (# of distinct types seen from p1's revealed mons)\n",
    "        # - (# of distinct types seen from p2's revealed mons).\n",
    "        #\n",
    "        # p2_seen_type_count:\n",
    "        #   Raw count of distinct types seen for p2.\n",
    "        # --------------------------------------------------------\n",
    "        def seen_types(names):\n",
    "            st = set()\n",
    "            for nm in names:\n",
    "                for tp in types_map.get(nm, [\"notype\",\"notype\"]):\n",
    "                    if tp != 'notype':\n",
    "                        st.add(tp)\n",
    "            return st\n",
    "\n",
    "        st1 = seen_types(revealed_p1)\n",
    "        st2 = seen_types(revealed_p2)\n",
    "        feats['type_seen_count_diff'] = int(len(st1) - len(st2))\n",
    "        feats['p2_seen_type_count'] = int(len(st2))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Expected damage features\n",
    "        #\n",
    "        # For each move we estimate \"expected damage\" as:\n",
    "        #   base power * accuracy * STAB * type multiplier\n",
    "        #\n",
    "        #   where:\n",
    "        #     - STAB = 1.5 if move type in user's types, else 1.0\n",
    "        #     - type multiplier = product of effectiveness vs opponent's types\n",
    "        #\n",
    "        # exp_dmg_stabtype_avg_diff:\n",
    "        #   (mean expected damage of p2 moves) - (mean expected damage of p1 moves)\n",
    "        # --------------------------------------------------------\n",
    "        def types_of(name):\n",
    "            return [x for x in types_map.get(name, [\"notype\",\"notype\"]) if x!='notype']\n",
    "\n",
    "        def type_multiplier(mv_type, opp_name):\n",
    "            if not mv_type: return 1.0\n",
    "            mult = 1.0\n",
    "            for ot in types_of(opp_name):\n",
    "                mult *= float(effectiveness.get(mv_type, {}).get(ot, 1.0))\n",
    "            return float(mult)\n",
    "\n",
    "        exp1 = []\n",
    "        exp2 = []\n",
    "        for i in range(den):\n",
    "            m1 = md1[i]; m2 = md2[i]\n",
    "            if m1.get('name'):\n",
    "                bp  = float(m1.get('base_power',0.0) or 0.0)\n",
    "                acc = float(m1['accuracy']) if (m1.get('accuracy') is not None) else 1.0\n",
    "                mv  = str(m1.get('type','') or '').lower()\n",
    "                mon = p1n[i] if i < len(p1n) else ''\n",
    "                stab = 1.5 if (mv and mv in types_of(mon)) else 1.0\n",
    "                opp = p2n[i] if i < len(p2n) else ''\n",
    "                tm  = type_multiplier(mv, opp)\n",
    "                exp1.append(bp * acc * stab * tm)\n",
    "            else:\n",
    "                exp1.append(0.0)\n",
    "            if m2.get('name'):\n",
    "                bp  = float(m2.get('base_power',0.0) or 0.0)\n",
    "                acc = float(m2['accuracy']) if (m2.get('accuracy') is not None) else 1.0\n",
    "                mv  = str(m2.get('type','') or '').lower()\n",
    "                mon = p2n[i] if i < len(p2n) else ''\n",
    "                stab = 1.5 if (mv and mv in types_of(mon)) else 1.0\n",
    "                opp = p1n[i] if i < len(p1n) else ''\n",
    "                tm  = type_multiplier(mv, opp)\n",
    "                exp2.append(bp * acc * stab * tm)\n",
    "            else:\n",
    "                exp2.append(0.0)\n",
    "\n",
    "        exp1 = np.array(exp1) if den else np.array([])\n",
    "        exp2 = np.array(exp2) if den else np.array([])\n",
    "        feats['exp_dmg_stabtype_avg_diff'] = float(\n",
    "            (np.mean(exp2)-np.mean(exp1)) if den else 0.0\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # switch_delta_exp_damage_diff:\n",
    "        #   For each player, consider only the turns where that player switches.\n",
    "        #   For such a turn i, compute:\n",
    "        #       delta = expected_damage[i] - expected_damage[i-1]\n",
    "        #   Then take the mean over all their switches.\n",
    "        #\n",
    "        #   switch_delta_exp_damage_diff =\n",
    "        #       mean_delta_for_p2_switches - mean_delta_for_p1_switches\n",
    "        #\n",
    "        #   Positive: p2's switches, on average, improve their offensive potential\n",
    "        #   more than p1's switches improve p1's.\n",
    "        # --------------------------------------------------------\n",
    "        def switch_delta(exp_vals, sw_idx):\n",
    "            vals=[]\n",
    "            for i in sw_idx:\n",
    "                prev = exp_vals[i-1] if i-1 >= 0 else 0.0\n",
    "                vals.append(float(exp_vals[i] - prev))\n",
    "            return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "        feats['switch_delta_exp_damage_diff'] = float(\n",
    "            switch_delta(exp2, sw2) - switch_delta(exp1, sw1)\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # confusion_exp_dmg_ratio_diff:\n",
    "        #   For each player we compute:\n",
    "        #       ratio_when_confused = mean(expected damage WHEN confused)\n",
    "        #                             / mean(expected damage when NOT confused)\n",
    "        #\n",
    "        #   confusion_exp_dmg_ratio_diff =\n",
    "        #       ratio_for_p2 - ratio_for_p1.\n",
    "        #\n",
    "        #   This tells us how much confusion \"depresses\" expected damage for each side.\n",
    "        # --------------------------------------------------------\n",
    "        def ratio_when(eff, exp_vals, tag):\n",
    "            with_tag  = [exp_vals[i] for i,s in enumerate(eff) if tag in s]\n",
    "            without   = [exp_vals[i] for i,s in enumerate(eff) if tag not in s]\n",
    "            mw = float(np.mean(with_tag)) if with_tag else 0.0\n",
    "            mo = float(np.mean(without))  if without else 0.0\n",
    "            return float(mw / (mo if mo!=0.0 else 1e-9))\n",
    "\n",
    "        feats['confusion_exp_dmg_ratio_diff'] = float(\n",
    "            ratio_when(eff2, exp2, 'confusion') - ratio_when(eff1, exp1, 'confusion')\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # substitute_break_rate_diff:\n",
    "        #   For each player we count:\n",
    "        #     - sub_t = number of turns where Substitute is up\n",
    "        #     - sub_b = number of times a Substitute disappears from one turn\n",
    "        #              to the next (i.e. is broken).\n",
    "        #   break_rate = sub_b / sub_t\n",
    "        #\n",
    "        #   substitute_break_rate_diff = break_rate_p1 - break_rate_p2.\n",
    "        #\n",
    "        #   Positive: p1's Substitutes get broken relatively more often than p2's\n",
    "        #   (conditional on having a sub up).\n",
    "        # --------------------------------------------------------\n",
    "        def breaks(eff):\n",
    "            return sum(1 for a,b in zip(eff, eff[1:]) if ('substitute' in a and 'substitute' not in b))\n",
    "\n",
    "        p1_sub_t = sum(1 for s in eff1 if 'substitute' in s)\n",
    "        p2_sub_t = sum(1 for s in eff2 if 'substitute' in s)\n",
    "        p1_sub_b = breaks(eff1) if den else 0\n",
    "        p2_sub_b = breaks(eff2) if den else 0\n",
    "        r1 = (p1_sub_b / p1_sub_t) if p1_sub_t else 0.0\n",
    "        r2 = (p2_sub_b / p2_sub_t) if p2_sub_t else 0.0\n",
    "        feats['substitute_break_rate_diff'] = float(r1 - r2)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Healing efficiency:\n",
    "        #\n",
    "        # heal_efficiency_diff:\n",
    "        #   For each side:\n",
    "        #     - total_loss = sum of damage taken\n",
    "        #     - total_heal = sum of healing done (based on HP recovery)\n",
    "        #     - heal_eff   = total_heal / total_loss\n",
    "        #\n",
    "        #   heal_efficiency_diff = heal_eff_p2 - heal_eff_p1.\n",
    "        #\n",
    "        # heal_mid_diff / heal_late_diff:\n",
    "        #   In the mid / late segments of the game we compute:\n",
    "        #     (healing done by p2) - (healing done by p1)\n",
    "        # --------------------------------------------------------\n",
    "        p1_loss_sum = float(sum(p1_loss)) if p1_loss else 0.0\n",
    "        p2_loss_sum = float(sum(p2_loss)) if p2_loss else 0.0\n",
    "        p1_heal_sum = float(sum(p1_heal)) if p1_heal else 0.0\n",
    "        p2_heal_sum = float(sum(p2_heal)) if p2_heal else 0.0\n",
    "        p1_he_eff = float(p1_heal_sum / (p1_loss_sum if p1_loss_sum!=0.0 else 1e-9))\n",
    "        p2_he_eff = float(p2_heal_sum / (p2_loss_sum if p2_loss_sum!=0.0 else 1e-9))\n",
    "        feats['heal_efficiency_diff'] = float(p2_he_eff - p1_he_eff)\n",
    "        feats['heal_mid_diff'] = float(\n",
    "            (sum(p2_heal[E:mid_end]) - sum(p1_heal[E:mid_end])) if den>1 else 0.0\n",
    "        )\n",
    "        feats['heal_late_diff'] = float(\n",
    "            (sum(p2_heal[-E:]) - sum(p1_heal[-E:])) if den>1 else 0.0\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # p2_max_boost_sum:\n",
    "        #   For every turn we sum all boost stages in p2's \"boosts\" dict\n",
    "        #   (e.g. +2 atk, +1 spe, etc.), then take the maximum over the battle.\n",
    "        #   Positive and large values indicate that at some point p2 was heavily boosted.\n",
    "        # --------------------------------------------------------\n",
    "        max_b2 = 0\n",
    "        for t in timeline:\n",
    "            b = (t['p2_pokemon_state'].get('boosts') or {})\n",
    "            s = int(sum(int(v) for v in b.values())) if b else 0\n",
    "            if s > max_b2:\n",
    "                max_b2 = s\n",
    "        feats['p2_max_boost_sum'] = int(max_b2)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # atk_edge_used:\n",
    "        #   p1_mean_atk_team:\n",
    "        #       average base Attack of p1's whole team (from team details).\n",
    "        #\n",
    "        #   p2_mean_atk_used:\n",
    "        #       usage-weighted average Attack of p2's mons that actually\n",
    "        #       came on the field (weighted by turns on field).\n",
    "        #\n",
    "        #   atk_edge_used = p2_mean_atk_used - p1_mean_atk_team.\n",
    "        #\n",
    "        #   Positive: p2's used attackers are, on average, stronger than\n",
    "        #   p1's team average Attack.\n",
    "        # --------------------------------------------------------\n",
    "        p1_team = battle.get('p1_team_details', []) or []\n",
    "        if p1_team:\n",
    "            p1_mean_atk_team = float(np.mean([int(p.get('base_atk',0)) for p in p1_team]))\n",
    "        else:\n",
    "            p1_mean_atk_team = 0.0\n",
    "        p2_mean_atk_used = wmean(c2, 'atk')\n",
    "        feats['atk_edge_used'] = float(p2_mean_atk_used - p1_mean_atk_team)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # hp_gap_slope_jump:\n",
    "        #   We look around the first faint event (\"first blood\") on any side.\n",
    "        #   We approximate the slope (trend) of hp_gap in a small window\n",
    "        #   BEFORE and AFTER the first faint turn; hp_gap_slope_jump is:\n",
    "        #\n",
    "        #       slope_post - slope_pre\n",
    "        #\n",
    "        #   Positive: after the first faint, hp_gap tends to increase more\n",
    "        #   (i.e. p2's advantage grows or p1's disadvantage increases).\n",
    "        # --------------------------------------------------------\n",
    "        fb_p1 = None\n",
    "        fb_p2 = None\n",
    "        for i in range(1, len(p2s)):\n",
    "            if p2s[i-1]!='fnt' and p2s[i]=='fnt':\n",
    "                fb_p1 = i+1; break\n",
    "        for i in range(1, len(p1s)):\n",
    "            if p1s[i-1]!='fnt' and p1s[i]=='fnt':\n",
    "                fb_p2 = i+1; break\n",
    "        fb_turns = [x for x in (fb_p1, fb_p2) if x is not None]\n",
    "        if den and len(hp_gap)>=2 and fb_turns:\n",
    "            fb = int(min(fb_turns))\n",
    "            pre_s = max(0, fb-1-5); pre_e = max(0, fb-1)\n",
    "            post_s = max(0, fb-1);  post_e = min(den, fb-1+5)\n",
    "            def slope(arr):\n",
    "                if len(arr) < 2: return 0.0\n",
    "                x = np.arange(len(arr))\n",
    "                try:\n",
    "                    return float(np.polyfit(x, arr, 1)[0])\n",
    "                except:\n",
    "                    return 0.0\n",
    "            slope_pre  = slope(hp_gap[pre_s:pre_e]) if pre_e-pre_s>=2 else 0.0\n",
    "            slope_post = slope(hp_gap[post_s:post_e]) if post_e-post_s>=2 else 0.0\n",
    "            feats['hp_gap_slope_jump'] = float(slope_post - slope_pre)\n",
    "        else:\n",
    "            feats['hp_gap_slope_jump'] = 0.0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # comeback_time_share_diff:\n",
    "        #   We look for \"sustained\" comebacks in hp_gap:\n",
    "        #   A comeback for one side is when hp_gap flips sign and then\n",
    "        #   stays in that sign for at least min_len turns.\n",
    "        #\n",
    "        #   sustained_share(arr, want_positive=True):\n",
    "        #       If want_positive=True, we look for a switch from negative to\n",
    "        #       positive hp_gap that persists; the returned value is a\n",
    "        #       fraction in [0,1] describing how \"late\" in the battle the\n",
    "        #       sustained positive run starts (relative to battle length).\n",
    "        #\n",
    "        #   p1_cb: comeback for p1, seen as sustained NEGATIVE hp_gap run\n",
    "        #   p2_cb: comeback for p2, seen as sustained NEGATIVE (-hp_gap) run\n",
    "        #\n",
    "        #   comeback_time_share_diff = p1_cb - p2_cb.\n",
    "        #   Positive: p1's comeback tends to happen later / more impressively\n",
    "        #   than p2's (in this crude metric).\n",
    "        # --------------------------------------------------------\n",
    "        def sustained_share(arr, want_positive=True, min_len=3):\n",
    "            if len(arr)==0: return 0.0\n",
    "            signs = np.sign(arr)\n",
    "            target = 1 if want_positive else -1\n",
    "            start=None\n",
    "            for i in range(1, len(signs)):\n",
    "                if (signs[i-1] == -target) and (signs[i] == target):\n",
    "                    start = i\n",
    "                    break\n",
    "            if start is None: return 0.0\n",
    "            streak=0\n",
    "            for j in range(start, len(signs)):\n",
    "                if signs[j] == target:\n",
    "                    streak += 1\n",
    "                    if streak >= min_len:\n",
    "                        return float((len(signs)-j) / len(signs))\n",
    "                else:\n",
    "                    break\n",
    "            return 0.0\n",
    "\n",
    "        p1_cb = float(sustained_share(hp_gap, want_positive=False))\n",
    "        p2_cb = float(sustained_share(-hp_gap, want_positive=False))\n",
    "        feats['comeback_time_share_diff'] = float(p1_cb - p2_cb)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Redundant assignments, but kept to preserve exact behaviour:\n",
    "        #   These lines simply re-assign already computed features.\n",
    "        #   They do not change any value, but they were present in the\n",
    "        #   original notebook and are left here to keep everything identical.\n",
    "        # --------------------------------------------------------\n",
    "        feats['status_diversity_p1'] = int(sd1)\n",
    "        feats['p2_seen_type_count']  = int(len(st2))\n",
    "        feats['bp_mean_p2'] = feats['bp_mean_p2']\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # Finally, we attach battle_id and (if present) player_won\n",
    "        # so that the model can use this table as input/output.\n",
    "        # --------------------------------------------------------\n",
    "        feats['battle_id'] = battle.get('battle_id')\n",
    "        if 'player_won' in battle:\n",
    "            feats['player_won'] = int(battle['player_won'])\n",
    "\n",
    "        rows.append(feats)\n",
    "\n",
    "    # Turn the list of feature dicts into a DataFrame\n",
    "    # and replace any missing values with 0\n",
    "    df = pd.DataFrame(rows).fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "# =========================\n",
    "# Our code is basically creating two dataset, a train and a test one, based on the train and test sets provided by the teachers. \n",
    "# In the train set there are 66 columns (features), that are: \"revealed_count_diff\",\"hp_edge_final\",\"status_severity_gap_final\",\"p1_alive_final\",\n",
    "# \"active_entropy_diff\",\"status_turns_advantage\",\"tox_ratio_diff\",\"forced_switch_share_diff\",\n",
    "# \"rs_hit_share_diff\",\"boom_count_diff\",\"counter_count_diff\",\"move_diversity_p1\",\n",
    "# \"used_mean_spe_diff\",\"p2_late_damage\",\"p1_status_mean_final\",\"attacks_rate_diff\",\n",
    "# \"bp_mean_p2\",\"hp_gap_peak_turn_share\",\"eff_speed_adv_share_p2\",\"types_last_round\",\n",
    "# \"atk_edge_used\",\"last_switch_turn_p1\",\"lead_type_edge\",\"hp_gap_slope_jump\",\n",
    "# \"initiative_late_diff\",\"initiative_early_diff\",\"comeback_time_share_diff\",\n",
    "# \"severe_status_early_share\",\"rec_share_diff\",\"switch_delta_exp_damage_diff\",\n",
    "# \"substitute_break_rate_diff\",\"confusion_late_share_diff\",\"status_diversity_p1\",\n",
    "# \"hp_gap_autocorr\",\"status_late_share_diff\",\"pingpong_switches_diff\",\n",
    "# \"same_move_streak_max_diff\",\"substitute_late_share_diff\",\"p1_sleep_streak_max\",\n",
    "# \"immune_count_diff\",\"heal_efficiency_diff\",\"exp_dmg_stabtype_avg_diff\",\"hp_gap_var\",\n",
    "# \"both_switched_share\",\"p1_switch_late_share\",\"p2_max_boost_sum\",\"status_diversity_diff\",\n",
    "# \"hp_gap_sign_flips\",\"reflect_early_share_diff\",\"lead_def_edge\",\"heal_mid_diff\",\n",
    "# \"confusion_exp_dmg_ratio_diff\",\"type_seen_count_diff\",\"eff_speed_edge_avg\",\n",
    "# \"heal_late_diff\",\"sleep_streak_max_diff\",\"p1_turns_par\",\"p2_used_count\",\n",
    "# \"hp_gap_peak\",\"p2_turns_brn\",\"p1_immune_count\",\"p2_seen_type_count\",\n",
    "# \"p1_pingpong_switches\",\"confusion_turns_diff\"\n",
    "\n",
    "# For an easy understanding of what these variables actually means, we have here a better description:\n",
    "\n",
    "# ============================================================\n",
    "# FEATURE GLOSSARY FOR build_features()\n",
    "# ============================================================\n",
    "#\n",
    "# 1. End-of-battle state (HP & status)\n",
    "# ------------------------------------\n",
    "# hp_edge_final\n",
    "#   Final HP edge: mean final HP% of player 2’s revealed Pokémon\n",
    "#   minus mean final HP% of player 1’s revealed Pokémon.\n",
    "#   > 0  -> p2 has more HP on average at the end.\n",
    "#\n",
    "# p1_alive_final\n",
    "#   Number of player 1’s Pokémon with HP% > 0 at the end of the battle.\n",
    "#\n",
    "# p1_status_mean_final\n",
    "#   Mean final status severity of player 1’s team, using the MAP_STATUS mapping.\n",
    "#\n",
    "# status_severity_gap_final\n",
    "#   Final status severity difference:\n",
    "#   (mean status severity of player 2’s team) − (mean status severity of player 1’s team).\n",
    "#   > 0  -> p2 is, on average, in a worse status condition than p1 at the end.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 2. Status over time\n",
    "# ------------------------------------------------------------\n",
    "# status_turns_advantage\n",
    "#   Sum over turns of (status severity for p1 − status severity for p2).\n",
    "#   > 0  -> p1 spends more turns under bad statuses than p2.\n",
    "#\n",
    "# tox_ratio_diff\n",
    "#   For each player we compute:\n",
    "#     tox_ratio = (# toxic turns) / (# poison+toxic turns).\n",
    "#   tox_ratio_diff = tox_ratio_p1 − tox_ratio_p2.\n",
    "#   > 0  -> relative to p2, p1 is more often under TOX (badly poisoned) when poisoned at all.\n",
    "#\n",
    "# severe_status_early_share\n",
    "#   Share of early turns (first third of the battle) where at least one side\n",
    "#   has a “severe” status (severity ≥ 2).\n",
    "#\n",
    "# status_diversity_p1\n",
    "#   Number of distinct non-\"nostatus\" conditions experienced by player 1.\n",
    "#\n",
    "# status_diversity_diff\n",
    "#   (status_diversity_p1) − (status diversity of p2).\n",
    "#\n",
    "# p1_turns_par\n",
    "#   Number of turns where player 1’s active Pokémon is paralyzed.\n",
    "#\n",
    "# p2_turns_brn\n",
    "#   Number of turns where player 2’s active Pokémon is burned.\n",
    "#\n",
    "# confusion_turns_diff\n",
    "#   (# of turns p1 is under confusion) − (# of turns p2 is under confusion).\n",
    "#\n",
    "# p1_sleep_streak_max\n",
    "#   Longest consecutive sequence of turns in which p1’s active Pokémon is asleep.\n",
    "#\n",
    "# sleep_streak_max_diff\n",
    "#   (p1’s longest sleep streak) − (p2’s longest sleep streak).\n",
    "#\n",
    "# confusion_late_share_diff\n",
    "#   In the last third of the battle:\n",
    "#   (share of turns p1 is confused) − (share of turns p2 is confused).\n",
    "#\n",
    "# confusion_exp_dmg_ratio_diff\n",
    "#   For each player we compute:\n",
    "#     ratio_confused = mean(expected damage when confused)\n",
    "#                      / mean(expected damage when not confused).\n",
    "#   Feature = ratio_confused_p2 − ratio_confused_p1.\n",
    "#   It measures how strongly confusion depresses expected damage for each side.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 3. Team revelation and type coverage\n",
    "# ------------------------------------------------------------\n",
    "# revealed_count_diff\n",
    "#   (# of distinct Pokémon that appeared on the field for p1)\n",
    "#   − (# for p2).\n",
    "#\n",
    "# type_seen_count_diff\n",
    "#   (# of distinct types seen on p1’s revealed Pokémon)\n",
    "#   − (# of distinct types seen on p2’s revealed Pokémon).\n",
    "#\n",
    "# p2_seen_type_count\n",
    "#   Number of distinct types seen on player 2’s revealed Pokémon.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 4. HP gap dynamics and damage/healing\n",
    "# ------------------------------------------------------------\n",
    "# hp_gap(t) = HP_p2(t) − HP_p1(t)\n",
    "#   > 0  -> p2 is ahead in HP at turn t\n",
    "#   < 0  -> p1 is ahead in HP at turn t\n",
    "#\n",
    "# p2_late_damage\n",
    "#   Total HP lost by player 2 in the last third of the battle.\n",
    "#\n",
    "# hp_gap_peak\n",
    "#   Maximum value of hp_gap over all turns.\n",
    "#   Measures p2’s best HP advantage during the battle.\n",
    "#\n",
    "# hp_gap_peak_turn_share\n",
    "#   (index_of_turn_with_max_hp_gap + 1) / total_turns.\n",
    "#   Where in the battle (0–1) the peak advantage for p2 occurs.\n",
    "#\n",
    "# hp_gap_var\n",
    "#   Variance of hp_gap over the whole battle.\n",
    "#   High variance means very swingy / volatile games.\n",
    "#\n",
    "# hp_gap_autocorr\n",
    "#   Autocorrelation of hp_gap between consecutive turns:\n",
    "#   corr(hp_gap[t], hp_gap[t+1]).\n",
    "#   High values mean advantages persist from turn to turn.\n",
    "#\n",
    "# hp_gap_sign_flips\n",
    "#   Number of times the sign of hp_gap changes (excluding zeros).\n",
    "#   Roughly: how often the lead switches between players.\n",
    "#\n",
    "# hp_gap_slope_jump\n",
    "#   Around the first faint (“first blood”), we estimate:\n",
    "#     slope_pre  = slope of hp_gap in the window BEFORE the faint.\n",
    "#     slope_post = slope of hp_gap in the window AFTER the faint.\n",
    "#   hp_gap_slope_jump = slope_post − slope_pre.\n",
    "#   > 0  -> after the first faint, hp_gap tends to increase more (p2 advantage grows).\n",
    "#\n",
    "# comeback_time_share_diff\n",
    "#   We look for “sustained” comebacks (sign change in hp_gap that persists).\n",
    "#   For each side we compute a share in [0,1] describing how late this\n",
    "#   sustained run happens.\n",
    "#   comeback_time_share_diff = comeback_share_p1 − comeback_share_p2.\n",
    "#   > 0  -> p1’s comeback tends to occur later / more pronounced than p2’s.\n",
    "#\n",
    "# heal_efficiency_diff\n",
    "#   For each player:\n",
    "#     loss = total damage taken\n",
    "#     heal = total healing done\n",
    "#     heal_eff = heal / loss\n",
    "#   Feature = heal_eff_p2 − heal_eff_p1.\n",
    "#\n",
    "# heal_mid_diff\n",
    "#   In the middle third of the battle:\n",
    "#   (total healing by p2) − (total healing by p1).\n",
    "#\n",
    "# heal_late_diff\n",
    "#   In the last third of the battle:\n",
    "#   (total healing by p2) − (total healing by p1).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 5. Move usage and offensive power\n",
    "# ------------------------------------------------------------\n",
    "# attacks_rate_diff\n",
    "#   (attacks per turn for p1) − (attacks per turn for p2),\n",
    "#   where an “attack” is any turn with a non-empty move name.\n",
    "#\n",
    "# bp_mean_p2\n",
    "#   Mean base power of moves used by player 2\n",
    "#   (only counting turns where a move is used and base_power is not None).\n",
    "#\n",
    "# exp_dmg_stabtype_avg_diff\n",
    "#   Expected damage is defined as:\n",
    "#     base_power × accuracy × STAB × type_multiplier\n",
    "#   where STAB = 1.5 if move type is among user’s types, else 1.0.\n",
    "#   Feature = (mean expected damage for p2) − (mean expected damage for p1).\n",
    "#\n",
    "# switch_delta_exp_damage_diff\n",
    "#   For switch turns only, we consider:\n",
    "#     delta = expected_damage[i] − expected_damage[i-1]\n",
    "#   For each player, we take the mean delta over all their switch turns.\n",
    "#   Feature = mean_delta_for_p2_switches − mean_delta_for_p1_switches.\n",
    "#   > 0  -> p2’s switches improve expected damage more than p1’s.\n",
    "#\n",
    "# same_move_streak_max_diff\n",
    "#   For each player we compute the longest streak of consecutive turns\n",
    "#   where they use the same move.\n",
    "#   Feature = max_streak_p1 − max_streak_p2.\n",
    "#\n",
    "# move_diversity_p1\n",
    "#   Number of distinct moves used by player 1 in the battle.\n",
    "#\n",
    "# rec_share_diff\n",
    "#   share of recovery moves for p1 − share of recovery moves for p2,\n",
    "#   where “recovery” moves are defined in RECOVERY_MOVES.\n",
    "#\n",
    "# boom_count_diff\n",
    "#   (# of Explosion/Selfdestruct used by p1) − (# used by p2).\n",
    "#\n",
    "# counter_count_diff\n",
    "#   (# of “Counter” used by p1) − (# used by p2).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 6. Speed, initiative, and boosts\n",
    "# ------------------------------------------------------------\n",
    "# used_mean_spe_diff\n",
    "#   Usage-weighted speed difference:\n",
    "#   (mean base Speed of p1’s used Pokémon, weighted by turns on field)\n",
    "#   − (mean base Speed of p2’s used Pokémon, weighted by turns on field).\n",
    "#\n",
    "# eff_speed_adv_share_p2\n",
    "#   Share of turns where p2’s “effective speed” is at least as high as p1’s.\n",
    "#   Effective speed combines:\n",
    "#     - base speed\n",
    "#     - boosts (Gen 1 style multipliers)\n",
    "#     - paralysis penalty (× 0.25 if PAR).\n",
    "#\n",
    "# eff_speed_edge_avg\n",
    "#   Mean (effective_speed_p2 − effective_speed_p1) over all turns.\n",
    "#\n",
    "# initiative_early_diff\n",
    "#   In the early third of the battle:\n",
    "#   we measure how often p1 base speed ≥ p2 base speed, turn by turn,\n",
    "#   and convert it to a “difference share” (share_p1 − share_p2).\n",
    "#\n",
    "# initiative_late_diff\n",
    "#   Same as initiative_early_diff but computed on the last third of the battle.\n",
    "#\n",
    "# last_switch_turn_p1\n",
    "#   Last turn index (1-based) where p1 switches.\n",
    "#   If p1 never switches, set to number_of_turns + 1.\n",
    "#\n",
    "# p2_max_boost_sum\n",
    "#   Over all turns, we look at p2’s boosts dict (stat stages) and sum them.\n",
    "#   p2_max_boost_sum is the maximum of this sum over the battle.\n",
    "#   Large positive values mean p2 was heavily boosted at some point.\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 7. Switching behaviour\n",
    "# ------------------------------------------------------------\n",
    "# forced_switch_share_diff\n",
    "#   A switch is considered \"forced\" if, right after the switch, the HP gap\n",
    "#   moves against the switching player:\n",
    "#     - for p1: hp_gap[i] − hp_gap[i−1] > 0 (gap moves towards p2)\n",
    "#     - for p2: hp_gap[i] − hp_gap[i−1] < 0 (gap moves towards p1)\n",
    "#   We compute the share of forced switches for each player.\n",
    "#   Feature = share_forced_p2 − share_forced_p1.\n",
    "#\n",
    "# p1_pingpong_switches\n",
    "#   Number of “ping-pong” patterns in p1’s active sequence:\n",
    "#   A → B → A (return to the same mon after exactly one different mon).\n",
    "#\n",
    "# pingpong_switches_diff\n",
    "#   (ping-pong count for p1) − (ping-pong count for p2).\n",
    "#\n",
    "# both_switched_share\n",
    "#   Share of turns (from turn 2 onwards) where BOTH players switch\n",
    "#   between turn i−1 and i.\n",
    "#\n",
    "# p1_switch_late_share\n",
    "#   In the last third of the battle:\n",
    "#   (number of turns where p1 switches) / (length of the late window).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 8. Field effects and immunities\n",
    "# ------------------------------------------------------------\n",
    "# rs_hit_share_diff\n",
    "#   For each player, we classify hits as:\n",
    "#     - super effective (se)\n",
    "#     - resisted (rs)\n",
    "#     - immune (im)\n",
    "#   rs_hit_share = rs_hits / total_effective_hits.\n",
    "#   Feature = rs_hit_share_p1 − rs_hit_share_p2.\n",
    "#\n",
    "# p1_immune_count\n",
    "#   Number of times p1’s moves hit into an immunity (no damage).\n",
    "#\n",
    "# immune_count_diff\n",
    "#   (# of immunities triggered by p1’s moves) − (# of immunities triggered by p2’s moves).\n",
    "#\n",
    "# substitute_late_share_diff\n",
    "#   In the last third of the battle:\n",
    "#   (share of turns with Substitute active on p1’s side)\n",
    "#   − (share of turns with Substitute on p2’s side).\n",
    "#\n",
    "# substitute_break_rate_diff\n",
    "#   For each player:\n",
    "#     sub_t = # of turns with Substitute active\n",
    "#     sub_b = # of times Substitute disappears between consecutive turns\n",
    "#   break_rate = sub_b / sub_t.\n",
    "#   Feature = break_rate_p1 − break_rate_p2.\n",
    "#\n",
    "# reflect_early_share_diff\n",
    "#   In the early third of the battle:\n",
    "#   (share of turns with Reflect on p1’s side)\n",
    "#   − (share of turns with Reflect on p2’s side).\n",
    "#\n",
    "# ------------------------------------------------------------\n",
    "# 9. Type matchups and team strength\n",
    "# ------------------------------------------------------------\n",
    "# lead_type_edge\n",
    "#   Type matchup edge on turn 1:\n",
    "#   aggregate advantage of p2’s lead types over p1’s lead types\n",
    "#   minus the reverse (p1’s types over p2’s).\n",
    "#   > 0  -> lead position is type-favorable to p2.\n",
    "#\n",
    "# lead_def_edge\n",
    "#   Base Defense difference between leads:\n",
    "#   (Defense of p2’s lead) − (Defense of p1’s lead).\n",
    "#\n",
    "# types_last_round\n",
    "#   Type edge on the final turn:\n",
    "#   sum of type advantages of p1’s active Pokémon vs p2’s\n",
    "#   minus the reverse (p2 vs p1).\n",
    "#   > 0  -> final board type advantage for p1.\n",
    "#\n",
    "# atk_edge_used\n",
    "#   Attack edge between teams:\n",
    "#     p1_mean_atk_team  = average base Attack of p1’s team from team details.\n",
    "#     p2_mean_atk_used  = usage-weighted mean base Attack of p2’s Pokémon that actually played.\n",
    "#   Feature = p2_mean_atk_used − p1_mean_atk_team.\n",
    "#\n",
    "# p2_used_count\n",
    "#   Number of distinct Pokémon actually used by player 2\n",
    "#   (i.e., took the field at least once).\n",
    "#\n",
    "# active_entropy_diff\n",
    "#   Entropy of the distribution of active Pokémon names for each player.\n",
    "#   High entropy means more diverse and balanced usage.\n",
    "#   Feature = H(p1_active) − H(p2_active).\n",
    "#   > 0  -> p1 used a more diverse mix of Pokémon than p2.\n",
    "#\n",
    "# ============================================================\n",
    "# End of feature glossary for build_features()\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# In the test set there are 65 columns (features): the features in train set but player_won.\n",
    "# Player_won is only in the train set because is the target variable.\n",
    "# Belowe we are actually computing the features we built above for each line of our jsonl datasets (each line is a pokemon battle).\n",
    "# We are calling build_features(...) on train and test to create\n",
    "# the final tables that we will feed into the models.\n",
    "# train_df has both features and the target player_won.\n",
    "# test_df has only features (we will predict player_won for each row).\n",
    "# ----------------------------------------------------------\n",
    "train_df = build_features(train_data)\n",
    "test_df  = build_features(test_data)\n",
    "\n",
    "print(f\"[FINAL] train_df: {train_df.shape}\")\n",
    "print(f\"[FINAL] test_df : {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2e16d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10000, 64),\n",
      "y_train shape: (10000,)\n",
      "X_test  shape: (5000, 64)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# In this second cell, we build X, y, X_test from the features table.\n",
    "# ------------------------------------------------------------\n",
    "# At this point we already have:\n",
    "#   - train_df: a big table of features for each battle, plus:\n",
    "#         * 'battle_id'   (identifier of the battle)\n",
    "#         * 'player_won'  (our target: 1 if player 1 won, 0 otherwise)\n",
    "#   - test_df : same features and 'battle_id', but WITHOUT 'player_won'\n",
    "#\n",
    "# In this small cell we:\n",
    "#   - find the feature columns that appear in BOTH train_df and test_df\n",
    "#   - drop 'battle_id' and 'player_won' (beacuse they are not input features)\n",
    "#   - we build:\n",
    "#       * X      -> training features (numpy array)\n",
    "#       * y      -> training labels (0/1)\n",
    "#       * X_test -> test features (numpy array)\n",
    "\n",
    "# In this cell we have taken our variables, we have sorted them and we have insert them in X and X_test.\n",
    "# X is the numpy array computed from the train dataset (this is why it has 10k rows)\n",
    "# X_test is the numpy array computed from the test dataset (this is why it has 5k rows).\n",
    "\n",
    "# We have stored the target variable in a numpy array as well, called y.\n",
    "\n",
    "# At the end of the cell we have added a sanity check, that prints the shape of X, X_test and y\n",
    "# ============================================================\n",
    "\n",
    "# Find all column names that are common between train and test\n",
    "cols = sorted(set(train_df.columns) & set(test_df.columns))\n",
    "\n",
    "# Feature columns are all common columns EXCEPT the identifiers/target.\n",
    "# We do not want to use 'battle_id' or 'player_won' as numeric features.\n",
    "f_cols = [c for c in cols if c not in (\"battle_id\", \"player_won\")]\n",
    "\n",
    "# y is the target vector (the thing we want to predict).\n",
    "# It is 1D: for each battle, 1 if player 1 won, 0 otherwise.\n",
    "y = train_df[\"player_won\"].astype(int).to_numpy()\n",
    "\n",
    "# X is the matrix of features for training.\n",
    "# Rows = battles, columns = features in f_cols.\n",
    "X = train_df[f_cols].to_numpy(dtype=float)\n",
    "\n",
    "# X_test is the same, but for the test set (where we do not know the labels).\n",
    "X_test = test_df[f_cols].to_numpy(dtype=float)\n",
    "\n",
    "\n",
    "# Sanity check: shapes of training and test matrices\n",
    "print(f\"X_train shape: {X.shape},\\ny_train shape: {y.shape}\")\n",
    "print(f\"X_test  shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a856a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "\n",
      " Logistic Regression\n",
      "CV accuracy: 0.8563\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\n",
      " AdaBoost\n",
      "CV accuracy: 0.8497\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n",
      "\n",
      " XGBoost\n",
      "CV accuracy: 0.8513\n",
      "[CV] lr: acc=0.8563\n",
      "[CV] ada: acc=0.8497\n",
      "[CV] xgb: acc=0.8513\n",
      "CV voting(soft, weighted): acc=0.8538 , weights={'lr': 0.7332496900000001, 'ada': 0.72199009, 'xgb': 0.7247116899999999}\n",
      "\n",
      ">>> Best model: voting (CV acc=0.8538)\n",
      "\n",
      "Train accuracy: 0.8726\n",
      "submission saved to: C:\\Users\\2003l\\OneDrive\\Documenti\\fds-pokemon-battles-prediction-2025\\submission_ens.csv\n",
      "\n",
      " SUMMARY \n",
      "lr: CV accuracy = 0.8563\n",
      "ada: CV accuracy = 0.8497\n",
      "xgb: CV accuracy = 0.8513\n",
      "Voting ensemble (soft, weighted): CV accuracy = 0.8538\n",
      "Training accuracy (full data, voting ensemble): 0.8726\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3) MODELS, HYPERPARAMETER SEARCH, ENSEMBLE, SUBMISSION\n",
    "# ------------------------------------------------------------\n",
    "# In this cell we:\n",
    "#   - define three base models:\n",
    "#       * Logistic Regression\n",
    "#       * AdaBoost (with tiny decision trees as weak learners)\n",
    "#       * XGBoost (gradient boosting)\n",
    "#   - set up hyperparameter grids for each model\n",
    "#   - run:\n",
    "#       * GridSearchCV for Logistic Regression as suggested by the professor and his TA. \n",
    "#       * GridSearchCV for AdaBoost, again as suggested by the professor and his TA. \n",
    "#       * RandomizedSearchCV for XGBoost\n",
    "#   - build a soft voting ensemble of the three tuned models\n",
    "#     (using their CV accuracy to weight them)\n",
    "#   - train the final ensemble on ALL the training data\n",
    "#   - generate predictions for the test set\n",
    "#   - save a CSV file we can submit to Kaggle / the competition.\n",
    "# You can think of this cell as the \"model playground\".\n",
    "# ============================================================\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Global configuration for our experiments:\n",
    "# We have decided to set the main starting parameters here at the start of our model.\n",
    "# The parameters are:\n",
    "# - SEED: for enanching reproducible randomness\n",
    "# - CV_FOLDS: how many cross-validation splits\n",
    "# - N_JOBS: how many CPU cores to use (-1 means \"all cores\" available)\n",
    "# - SCORING: which metric we use to judge models (here: accuracy)\n",
    "\n",
    "SEED       = 42\n",
    "CV_FOLDS   = 5\n",
    "N_JOBS     = -1\n",
    "SCORING    = \"accuracy\"\n",
    "\n",
    "np.random.seed(SEED)\n",
    "cv5 = StratifiedKFold(n_splits=CV_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "def cv_mean_acc(model, X, y):\n",
    "    \"\"\"Run cross-validation for this model and return the mean accuracy.\n",
    "    It takes a model (like LogisticRegression or a Pipeline),\n",
    "    trains and evaluates it across the folds in cv5, and then\n",
    "    returns the average accuracy.\n",
    "    \"\"\"\n",
    "    scores = cross_val_score(model, X, y, cv=cv5, scoring=SCORING, n_jobs=N_JOBS)\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "\n",
    "# PIPELINES \n",
    "# Here we build 3 different machine learning pipelines.\n",
    "# A pipeline is like a small factory that takes in raw features\n",
    "# and spits out predictions. It can contain multiple steps\n",
    "# (for example: scaling, then a classifier).\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "# Here we run GridSearchCV on the Logistic Regression pipeline.\n",
    "# It will try all combinations in param_grid_lr, using cross-validation,\n",
    "# and pick the hyperparameters with the best mean accuracy.\n",
    "\n",
    "# This is a linear model. We put it inside a Pipeline\n",
    "# with a StandardScaler to make the features more comparable in scale.\n",
    "\n",
    "pipe_lr = Pipeline([\n",
    "    (\"scale\", StandardScaler(with_mean=False)),\n",
    "    (\"clf\",   LogisticRegression(random_state=SEED))\n",
    "])\n",
    "\n",
    "# AdaBoost\n",
    "# Same idea as above, but now for the AdaBoost pipeline.\n",
    "# We try different numbers of estimators, learning rates and tree depths.\n",
    "\n",
    "# AdaBoost is an ensemble of many small decision trees (\"weak learners\").\n",
    "# Each tiny tree is not very powerful on its own, but together they can\n",
    "# capture non-linear patterns. Here we use max_depth=1 trees (decision stumps).\n",
    "\n",
    "pipe_ada = Pipeline([\n",
    "    (\"ada\", AdaBoostClassifier(\n",
    "        estimator=DecisionTreeClassifier(max_depth=1, random_state=SEED),\n",
    "        random_state=SEED\n",
    "    )),\n",
    "])\n",
    "\n",
    "# XGBoost\n",
    "# XGBoost \n",
    "# For XGBoost the grid is big, so we randomly sample a subset\n",
    "# of the combinations (n_iter) instead of exploring all of them.\n",
    "# This avoid being stack running the code for hours.\n",
    "# In particular we are implementing a powerful gradient boosting model that builds trees one by one,\n",
    "# each new tree trying to correct the mistakes of the previous ones.\n",
    "# It is usually very strong on tabular data like this.\n",
    "\n",
    "pipe_xgb = Pipeline([\n",
    "    (\"xgb\", XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        n_jobs=N_JOBS,\n",
    "        random_state=SEED\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "# Hyperparameter grid for Logistic Regression:\n",
    "# - solver, penalty: we focus on liblinear + L1 here\n",
    "# - C: strength of regularization (higher C = weaker regularization)\n",
    "# - tol: convergence tolerance for the optimizer\n",
    "# - class_weight: we optionally let the model handle class imbalance\n",
    "# - max_iter: how many iterations the solver is allowed to run\n",
    "\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"clf__solver\":       [\"liblinear\"],\n",
    "    \"clf__penalty\":      [\"l1\"],\n",
    "    \"clf__C\":            [2.50, 3.00, 3.25, 3.50, 4.00],\n",
    "    \"clf__tol\":          [1e-6, 5e-6, 1e-5, 5e-5, 1e-4],\n",
    "    \"clf__class_weight\": [None, \"balanced\"],\n",
    "    \"clf__max_iter\":     [6000, 10000],\n",
    "}\n",
    "\n",
    "# Hyperparameter grid for AdaBoost:\n",
    "# - n_estimators: how many small trees\n",
    "# - learning_rate: how fast we update the ensemble\n",
    "# - estimator: the base decision tree (here we try depths 1 and 2)\n",
    "\n",
    "param_grid_ada = {\n",
    "    \"ada__algorithm\":      [\"SAMME.R\"],\n",
    "    \"ada__n_estimators\":   [270, 300, 330, 350],\n",
    "    \"ada__learning_rate\":  [0.15, 0.20, 0.26, 0.38],\n",
    "    \"ada__estimator\":      [DecisionTreeClassifier(max_depth=d, random_state=SEED) for d in [1, 2]],\n",
    "}\n",
    "\n",
    "# Hyperparameter grid for XGBoost:\n",
    "# - n_estimators: number of boosting rounds (trees)\n",
    "# - max_depth: depth of each tree\n",
    "# - learning_rate: step size shrinkage\n",
    "# - subsample / colsample_bytree: how much data/features each tree sees\n",
    "# - min_child_weight, reg_alpha, reg_lambda, gamma: regularization terms\n",
    "\n",
    "param_grid_xgb = {\n",
    "    \"xgb__n_estimators\":     [800, 850, 900, 950, 1000],\n",
    "    \"xgb__max_depth\":        [4, 5],\n",
    "    \"xgb__learning_rate\":    [0.015, 0.020, 0.022],\n",
    "    \"xgb__subsample\":        [0.55, 0.60],\n",
    "    \"xgb__colsample_bytree\": [0.60, 0.65],\n",
    "    \"xgb__min_child_weight\": [2, 3],\n",
    "    \"xgb__reg_alpha\":        [0.00, 0.03, 0.05],\n",
    "    \"xgb__reg_lambda\":       [0.80, 1.00],\n",
    "    \"xgb__gamma\":            [0.10, 0.20, 0.30],\n",
    "}\n",
    "\n",
    "def grid_size(grid: dict) -> int:\n",
    "    \"\"\"Return how many total combinations are in a parameter grid.\n",
    "    We just multiply the lengths of the value lists in the dict.\n",
    "    \"\"\"\n",
    "\n",
    "    n = 1\n",
    "    for v in grid.values():\n",
    "        n *= len(v)\n",
    "    return n\n",
    "\n",
    "\n",
    "# TUNING\n",
    "# In this section we search for good hyperparameters for each model.\n",
    "# - For Logistic Regression and AdaBoost we do a full GridSearchCV.\n",
    "# - For XGBoost we do a RandomizedSearchCV because the grid is large.\n",
    "\n",
    "\n",
    "# Logistic Regression\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=param_grid_lr,\n",
    "    cv=cv5,\n",
    "    scoring=SCORING,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=1\n",
    ")\n",
    "gs_lr.fit(X, y)\n",
    "lr_best      = gs_lr.best_estimator_\n",
    "lr_best_acc  = gs_lr.best_score_\n",
    "\n",
    "print(\"\\n Logistic Regression\")\n",
    "print(\"CV accuracy:\", round(lr_best_acc, 4))\n",
    "\n",
    "# AdaBoost\n",
    "gs_ada = GridSearchCV(\n",
    "    estimator=pipe_ada,\n",
    "    param_grid=param_grid_ada,\n",
    "    cv=cv5,\n",
    "    scoring=SCORING,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=1\n",
    ")\n",
    "gs_ada.fit(X, y)\n",
    "ada_best     = gs_ada.best_estimator_\n",
    "ada_best_acc = gs_ada.best_score_\n",
    "\n",
    "print(\"\\n AdaBoost\")\n",
    "print(\"CV accuracy:\", round(ada_best_acc, 4))\n",
    "\n",
    "# XGBoost \n",
    "total_xgb = grid_size(param_grid_xgb)\n",
    "n_iter_xgb = min(200, total_xgb)\n",
    "\n",
    "rs_xgb = RandomizedSearchCV(\n",
    "    estimator=pipe_xgb,\n",
    "    param_distributions=param_grid_xgb,\n",
    "    n_iter=n_iter_xgb,\n",
    "    cv=cv5,\n",
    "    scoring=SCORING,\n",
    "    n_jobs=N_JOBS,\n",
    "    verbose=1,\n",
    "    random_state=SEED\n",
    ")\n",
    "rs_xgb.fit(X, y)\n",
    "xgb_best     = rs_xgb.best_estimator_\n",
    "xgb_best_acc = rs_xgb.best_score_\n",
    "\n",
    "print(\"\\n XGBoost\")\n",
    "print(\"CV accuracy:\", round(xgb_best_acc, 4))\n",
    "\n",
    "estimators = [\n",
    "    (\"lr\",  lr_best),\n",
    "    (\"ada\", ada_best),\n",
    "    (\"xgb\", xgb_best),\n",
    "]\n",
    "\n",
    "# SOFT VOTING \n",
    "# Once we have the best version of each base model (LR, Ada, XGB),\n",
    "# we combine them into a soft voting ensemble.\n",
    "# \"Soft\" means that we average the predicted probabilities from each model,\n",
    "# instead of just voting on hard class labels 0/1.\n",
    "# We also give each model a weight based on its CV accuracy, so better\n",
    "# models have more influence in the final decision.\n",
    "\n",
    "cv_scores = {}\n",
    "for name, mdl in estimators:\n",
    "    acc = cv_mean_acc(mdl, X, y)\n",
    "    cv_scores[name] = acc\n",
    "    print(f\"[CV] {name}: acc={acc:.4f}\")\n",
    "\n",
    "weights = [max(1e-6, cv_scores[name] ** 2) for name, _ in estimators]\n",
    "vote = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting=\"soft\",\n",
    "    weights=weights,\n",
    "    n_jobs=N_JOBS\n",
    ")\n",
    "vote_acc = cv_mean_acc(vote, X, y)\n",
    "print(f\"CV voting(soft, weighted): acc={vote_acc:.4f} , weights={dict(zip([n for n, _ in estimators], weights))}\")\n",
    "\n",
    "\n",
    "best_name  = \"voting\"\n",
    "best_model = vote\n",
    "best_cv    = vote_acc\n",
    "print(f\"\\n>>> Best model: {best_name} (CV acc={best_cv:.4f})\")\n",
    "\n",
    "# SUBMISSION \n",
    "# Here we train the chosen model (the voting ensemble) on ALL the training data,\n",
    "# Here we are building the submission DataFrame for the competition/evaluation.\n",
    "\n",
    "best_model.fit(X, y)\n",
    "train_pred = best_model.predict(X)\n",
    "train_acc  = accuracy_score(y, train_pred)\n",
    "print(f\"\\nTrain accuracy: {train_acc:.4f}\")\n",
    "\n",
    "proba = best_model.predict_proba(X_test)[:, 1]\n",
    "pred  = (proba >= 0.5).astype(int)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"battle_id\": test_df[\"battle_id\"],\n",
    "    \"player_won\": pred\n",
    "})\n",
    "\n",
    "out_path = (Path.cwd() / \"submission_ens.csv\").resolve()\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(f\"submission saved to: {out_path}\")\n",
    "\n",
    "# SUMMARY\n",
    "# Finally, we print a short summary of the cross-validation scores for the\n",
    "# individual models and for the ensemble, plus the training accuracy.\n",
    "\n",
    "print(\"\\n SUMMARY \")\n",
    "for name, acc in cv_scores.items():\n",
    "    print(f\"{name}: CV accuracy = {acc:.4f}\")\n",
    "print(f\"Voting ensemble (soft, weighted): CV accuracy = {vote_acc:.4f}\")\n",
    "print(f\"Training accuracy (full data, voting ensemble): {train_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
